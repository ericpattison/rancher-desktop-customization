---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-lgtm
  namespace: monitoring
  labels:
    app: otel-lgtm
data:
  otelcol-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
      prometheus/collector:
        config:
          scrape_configs:
          - job_name: 'opentelemetry-collector'
            static_configs:
            - targets: ['localhost:8888']
          - job_name: 'kubernetes-cadvisor'
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
            - role: node
            relabel_configs:
            - replacement: kubernetes.default.svc.cluster.local:443
              target_label: __address__
            - regex: (.+)
              replacement: /api/v1/nodes/$${1}/proxy/metrics/cadvisor
              source_labels:
              - __meta_kubernetes_node_name
              target_label: __metrics_path__
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: false
              server_name: kubernetes
          - job_name: 'kubernetes-kubelet'
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
            - role: node
            relabel_configs:
            - replacement: kubernetes.default.svc.cluster.local:443
              target_label: __address__
            - regex: (.+)
              replacement: /api/v1/nodes/$${1}/proxy/metrics
              source_labels:
              - __meta_kubernetes_node_name
              target_label: __metrics_path__
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: false
              server_name: kubernetes
          - job_name: 'kubernetes-apiservers'
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            kubernetes_sd_configs:
            - role: endpoints
              namespaces:
                names:
                - default
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: false
              server_name: kubernetes
            relabel_configs:
            - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              action: keep
              regex: kubernetes;https
            - action: replace
              source_labels:
              - __meta_kubernetes_namespace
              target_label: Namespace
            - action: replace
              source_labels:
              - __meta_kubernetes_service_name
              target_label: Service
          - job_name: kube-state-metrics
            kubernetes_sd_configs:
            - role: pod
            relabel_configs:
            - action: keep
              regex: kube-state-metrics
              source_labels:
              - __meta_kubernetes_pod_label_app_kubernetes_io_name
          - job_name: node-exporter
            kubernetes_sd_configs:
            - role: pod
            relabel_configs:
            - action: keep
              regex: prometheus-node-exporter.*
              source_labels:
              - __meta_kubernetes_pod_label_app_kubernetes_io_name
            - action: replace
              source_labels:
              - __meta_kubernetes_pod_node_name
              target_label: instance
            - action: replace
              source_labels:
              - __meta_kubernetes_namespace
              target_label: namespace
    processors:
      batch:
    exporters:
      otlphttp/metrics:
        endpoint: http://localhost:9090/api/v1/otlp
      otlphttp/traces:
        endpoint: http://localhost:4418
      otlphttp/logs:
        endpoint: http://localhost:3100/otlp
      logging/metrics:
        verbosity: detailed
      logging/traces:
        verbosity: detailed
      logging/logs:
        verbosity: detailed
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlphttp/traces]
          #exporters: [otlphttp/traces,logging/traces]
        metrics:
          receivers: [otlp,prometheus/collector]
          processors: [batch]
          exporters: [otlphttp/metrics]
          #exporters: [otlphttp/metrics,logging/metrics]
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlphttp/logs]
          #exporters: [otlphttp/logs,logging/logs]
  otelcol-datasources.yaml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      uid: prometheus
      url: http://localhost:9090
      jsonData:
        timeInterval: 60s
        exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: tempo
          urlDisplayLabel: 'Trace: $${__value.raw}'
    - name: Tempo
      type: tempo
      uid: tempo
      url: http://localhost:3200
      jsonData:
        tracesToLogsV2:
        customQuery: true
        datasourceUid: 'loki'
        query: '{$${__tags}} | trace_id = "$${__trace.traceId}"'
        tags:
        - key: 'service.name'
          value: 'service_name'
        serviceMap:
          datasourceUid: 'prometheus'
        search:
          hide: false
        nodeGraph:
          enabled: true
        lokiSearch:
          datasourceUid: 'loki'
    - name: Loki
      type: loki
      uid: loki
      url: http://localhost:3100
      jsonData:
        derivedFields:
        - name: 'trace_id'
          matcherType: 'label'
          matcherRegex: 'trace_id'
          url: '$${__value.raw}'
          datasourceUid: 'tempo'
          urlDisplayLabel: 'Trace: $${__value.raw}'
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    kubernetes.io/enforce-mountable-secrets: "true"
  name: otel-lgtm
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
  - apiGroups:  ['*']
    resources: ['*']
    verbs:  ['*']
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
subjects:
  - kind: ServiceAccount
    name: otel-lgtm
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: otel-collector
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: otel-lgtm
  namespace: monitoring
  labels:
    type: local
spec:
  storageClassName: local-path
  capacity:
    storage: 10Gi
  accessModes:
  - ReadWriteOnce
  hostPath:
    path: "/mnt/wsl/k8s/otel-lgtm"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: otel-lgtm
  namespace: monitoring
spec:
  storageClassName: local-path
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-lgtm
  namespace: monitoring
  labels:
    app: otel-lgtm
spec:
  selector:
    matchLabels:
      app: otel-lgtm
  template:
    metadata:
      name: otel-lgtm
      labels:
        app: otel-lgtm
    spec:
      serviceAccountName: otel-lgtm
      containers:
      - name: otel-lgtm
        image: grafana/otel-lgtm:0.6.0
        ports:
        - name: prometheus
          containerPort: 9090
        - name: grafana
          containerPort: 3000
        - name: otel-grpc
          containerPort: 4317
        - name: otel-http
          containerPort: 4318
        env:
        - name: GF_PATHS_DATA
          value: /data/grafana
        resources:
          requests:
            cpu: 100m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        volumeMounts:
        - name: otel-lgtm
          mountPath: /data/grafana
          subPath: grafana
        - name: otel-lgtm
          mountPath: /loki
          subPath: loki
        - name: otel-lgtm
          mountPath: /data/prometheus
          subPath: prometheus
        - name: otelcol-config
          mountPath: /otel-lgtm/otelcol-config.yaml
          subPath: otelcol-config.yaml
        - name: otelcol-config
          mountPath: /otel-lgtm/grafana/conf/provisioning/datasources/grafana-datasources.yaml
          subPath: otelcol-datasources.yaml
      volumes:
      - name: otel-lgtm
        persistentVolumeClaim:
          claimName: otel-lgtm
      - name: otelcol-config
        configMap:
          name: otel-lgtm
---
apiVersion: v1
kind: Service
metadata:
  name: otel-lgtm
  namespace: monitoring
spec:
  selector:
    app: otel-lgtm
  ports:
  - name: grafana
    port: 3000
    targetPort: grafana
  - name: otel-grpc
    port: 4317
    targetPort: otel-grpc
  - name: otel-http
    port: 4318
    targetPort: otel-http
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: otel-lgtm
  namespace: monitoring
spec:
  ingressClassName: nginx
  rules:
  - host: "grafana.lvh.me"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: otel-lgtm
            port:
              number: 3000
---
